<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pina.solvers.garom &mdash; PINA 0.1.1.post2407 documentation</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/pina_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1.1.post2407
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Package Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_rst/_code.html">API</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting Started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_rst/_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_rst/_tutorial.html">Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">Community:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_team.html">Team &amp; Fundings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_rst/_contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_LICENSE.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_cite.html">Cite PINA</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PINA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pina.solvers.garom</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pina.solvers.garom</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Module for GAROM &quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">LRScheduler</span>  <span class="c1"># torch &gt;= 2.0</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_LRScheduler</span> <span class="k">as</span> <span class="n">LRScheduler</span><span class="p">,</span>
    <span class="p">)</span>  <span class="c1"># torch &lt; 2.0</span>

<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ConstantLR</span>
<span class="kn">from</span> <span class="nn">.solver</span> <span class="kn">import</span> <span class="n">SolverInterface</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">check_consistency</span>
<span class="kn">from</span> <span class="nn">..loss</span> <span class="kn">import</span> <span class="n">LossInterface</span><span class="p">,</span> <span class="n">PowerLoss</span>
<span class="kn">from</span> <span class="nn">torch.nn.modules.loss</span> <span class="kn">import</span> <span class="n">_Loss</span>


<div class="viewcode-block" id="GAROM"><a class="viewcode-back" href="../../../_rst/solvers/garom.html#pina.solvers.garom.GAROM">[docs]</a><span class="k">class</span> <span class="nc">GAROM</span><span class="p">(</span><span class="n">SolverInterface</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    GAROM solver class. This class implements Generative Adversarial</span>
<span class="sd">    Reduced Order Model solver, using user specified ``models`` to solve</span>
<span class="sd">    a specific order reduction``problem``.</span>

<span class="sd">    .. seealso::</span>

<span class="sd">        **Original reference**: Coscia, D., Demo, N., &amp; Rozza, G. (2023).</span>
<span class="sd">        *Generative Adversarial Reduced Order Modelling*.</span>
<span class="sd">        DOI: `arXiv preprint arXiv:2305.15881.</span>
<span class="sd">        &lt;https://doi.org/10.48550/arXiv.2305.15881&gt;`_.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">problem</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">,</span>
        <span class="n">discriminator</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="n">optimizer_generator_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">},</span>
        <span class="n">optimizer_discriminator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="n">optimizer_discriminator_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">},</span>
        <span class="n">scheduler_generator</span><span class="o">=</span><span class="n">ConstantLR</span><span class="p">,</span>
        <span class="n">scheduler_generator_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;factor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;total_iters&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
        <span class="n">scheduler_discriminator</span><span class="o">=</span><span class="n">ConstantLR</span><span class="p">,</span>
        <span class="n">scheduler_discriminator_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;factor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;total_iters&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
        <span class="n">gamma</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">lambda_k</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="n">regularizer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param AbstractProblem problem: The formualation of the problem.</span>
<span class="sd">        :param torch.nn.Module generator: The neural network model to use</span>
<span class="sd">            for the generator.</span>
<span class="sd">        :param torch.nn.Module discriminator: The neural network model to use</span>
<span class="sd">            for the discriminator.</span>
<span class="sd">        :param torch.nn.Module loss: The loss function used as minimizer,</span>
<span class="sd">            default ``None``. If ``loss`` is ``None`` the defualt</span>
<span class="sd">            ``PowerLoss(p=1)`` is used, as in the original paper.</span>
<span class="sd">        :param torch.optim.Optimizer optimizer_generator: The neural</span>
<span class="sd">            network optimizer to use for the generator network</span>
<span class="sd">            , default is `torch.optim.Adam`.</span>
<span class="sd">        :param dict optimizer_generator_kwargs: Optimizer constructor keyword</span>
<span class="sd">            args. for the generator.</span>
<span class="sd">        :param torch.optim.Optimizer optimizer_discriminator: The neural</span>
<span class="sd">            network optimizer to use for the discriminator network</span>
<span class="sd">            , default is `torch.optim.Adam`.</span>
<span class="sd">        :param dict optimizer_discriminator_kwargs: Optimizer constructor keyword</span>
<span class="sd">            args. for the discriminator.</span>
<span class="sd">        :param torch.optim.LRScheduler scheduler_generator: Learning</span>
<span class="sd">            rate scheduler for the generator.</span>
<span class="sd">        :param dict scheduler_generator_kwargs: LR scheduler constructor keyword args.</span>
<span class="sd">        :param torch.optim.LRScheduler scheduler_discriminator: Learning</span>
<span class="sd">            rate scheduler for the discriminator.</span>
<span class="sd">        :param dict scheduler_discriminator_kwargs: LR scheduler constructor keyword args.</span>
<span class="sd">        :param gamma: Ratio of expected loss for generator and discriminator, defaults to 0.3.</span>
<span class="sd">        :type gamma: float</span>
<span class="sd">        :param lambda_k: Learning rate for control theory optimization, defaults to 0.001.</span>
<span class="sd">        :type lambda_k: float</span>
<span class="sd">        :param regularizer: Regularization term in the GAROM loss, defaults to False.</span>
<span class="sd">        :type regularizer: bool</span>

<span class="sd">        .. warning::</span>
<span class="sd">            The algorithm works only for data-driven model. Hence in the ``problem`` definition</span>
<span class="sd">            the codition must only contain ``input_points`` (e.g. coefficient parameters, time</span>
<span class="sd">            parameters), and ``output_points``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">],</span>
            <span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span>
            <span class="n">optimizers</span><span class="o">=</span><span class="p">[</span><span class="n">optimizer_generator</span><span class="p">,</span> <span class="n">optimizer_discriminator</span><span class="p">],</span>
            <span class="n">optimizers_kwargs</span><span class="o">=</span><span class="p">[</span>
                <span class="n">optimizer_generator_kwargs</span><span class="p">,</span>
                <span class="n">optimizer_discriminator_kwargs</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># set automatic optimization for GANs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># set loss</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">PowerLoss</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># check consistency</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">scheduler_generator</span><span class="p">,</span> <span class="n">LRScheduler</span><span class="p">,</span> <span class="n">subclass</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">scheduler_generator_kwargs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">scheduler_discriminator</span><span class="p">,</span> <span class="n">LRScheduler</span><span class="p">,</span> <span class="n">subclass</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">scheduler_discriminator_kwargs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">LossInterface</span><span class="p">,</span> <span class="n">_Loss</span><span class="p">))</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">lambda_k</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">check_consistency</span><span class="p">(</span><span class="n">regularizer</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>

        <span class="c1"># assign schedulers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">scheduler_generator</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">scheduler_generator_kwargs</span>
            <span class="p">),</span>
            <span class="n">scheduler_discriminator</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">**</span><span class="n">scheduler_discriminator_kwargs</span>
            <span class="p">),</span>
        <span class="p">]</span>

        <span class="c1"># loss and writer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="c1"># began hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_k</span> <span class="o">=</span> <span class="n">lambda_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<div class="viewcode-block" id="GAROM.forward"><a class="viewcode-back" href="../../../_rst/solvers/garom.html#pina.solvers.garom.GAROM.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mc_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward step for GAROM solver</span>

<span class="sd">        :param x: The input tensor.</span>
<span class="sd">        :type x: torch.Tensor</span>
<span class="sd">        :param mc_steps: Number of montecarlo samples to approximate the</span>
<span class="sd">            expected value, defaults to 20.</span>
<span class="sd">        :type mc_steps: int</span>
<span class="sd">        :param variance: Returining also the sample variance of the solution, defaults to False.</span>
<span class="sd">        :type variance: bool</span>
<span class="sd">        :return: The expected value of the generator distribution. If ``variance=True`` also the</span>
<span class="sd">            sample variance is returned.</span>
<span class="sd">        :rtype: torch.Tensor | tuple(torch.Tensor, torch.Tensor)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># sampling</span>
        <span class="n">field_sample</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mc_steps</span><span class="p">)]</span>
        <span class="n">field_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">field_sample</span><span class="p">)</span>

        <span class="c1"># extract mean</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">field_sample</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">variance</span><span class="p">:</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">field_sample</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span>

        <span class="k">return</span> <span class="n">mean</span></div>

<div class="viewcode-block" id="GAROM.configure_optimizers"><a class="viewcode-back" href="../../../_rst/solvers/garom.html#pina.solvers.garom.GAROM.configure_optimizers">[docs]</a>    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimizer configuration for the GAROM</span>
<span class="sd">        solver.</span>

<span class="sd">        :return: The optimizers and the schedulers</span>
<span class="sd">        :rtype: tuple(list, list)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span></div>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># sampling</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">snapshots</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private method to train the generator network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_generator</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">generated_snapshots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

        <span class="c1"># generator loss</span>
        <span class="n">r_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">snapshots</span><span class="p">,</span> <span class="n">generated_snapshots</span><span class="p">)</span>
        <span class="n">d_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">forward_map</span><span class="p">(</span>
            <span class="p">[</span><span class="n">generated_snapshots</span><span class="p">,</span> <span class="n">parameters</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">g_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">d_fake</span><span class="p">,</span> <span class="n">generated_snapshots</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">*</span> <span class="n">r_loss</span>
        <span class="p">)</span>

        <span class="c1"># backward step</span>
        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">r_loss</span><span class="p">,</span> <span class="n">g_loss</span>

    <span class="k">def</span> <span class="nf">_train_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">snapshots</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private method to train the discriminator network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_discriminator</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Generate a batch of images</span>
        <span class="n">generated_snapshots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

        <span class="c1"># Discriminator pass</span>
        <span class="n">d_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">forward_map</span><span class="p">([</span><span class="n">snapshots</span><span class="p">,</span> <span class="n">parameters</span><span class="p">])</span>
        <span class="n">d_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">forward_map</span><span class="p">(</span>
            <span class="p">[</span><span class="n">generated_snapshots</span><span class="p">,</span> <span class="n">parameters</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># evaluate loss</span>
        <span class="n">d_loss_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">d_real</span><span class="p">,</span> <span class="n">snapshots</span><span class="p">)</span>
        <span class="n">d_loss_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">d_fake</span><span class="p">,</span> <span class="n">generated_snapshots</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="n">d_loss</span> <span class="o">=</span> <span class="n">d_loss_real</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">*</span> <span class="n">d_loss_fake</span>

        <span class="c1"># backward step</span>
        <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">d_loss_real</span><span class="p">,</span> <span class="n">d_loss_fake</span><span class="p">,</span> <span class="n">d_loss</span>

    <span class="k">def</span> <span class="nf">_update_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_loss_real</span><span class="p">,</span> <span class="n">d_loss_fake</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private method to Update the weights of the generator and discriminator</span>
<span class="sd">        networks.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">d_loss_real</span> <span class="o">-</span> <span class="n">d_loss_fake</span><span class="p">)</span>

        <span class="c1"># Update weight term for fake samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_k</span> <span class="o">*</span> <span class="n">diff</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Constraint to interval [0, 1]</span>
        <span class="k">return</span> <span class="n">diff</span>

<div class="viewcode-block" id="GAROM.training_step"><a class="viewcode-back" href="../../../_rst/solvers/garom.html#pina.solvers.garom.GAROM.training_step">[docs]</a>    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;GAROM solver training step.</span>

<span class="sd">        :param batch: The batch element in the dataloader.</span>
<span class="sd">        :type batch: tuple</span>
<span class="sd">        :param batch_idx: The batch index.</span>
<span class="sd">        :type batch_idx: int</span>
<span class="sd">        :return: The sum of the loss functions.</span>
<span class="sd">        :rtype: LabelTensor</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">condition_idx</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;condition&quot;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">condition_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">condition_idx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">condition_idx</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

            <span class="n">condition_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataloader</span><span class="o">.</span><span class="n">condition_names</span><span class="p">[</span><span class="n">condition_id</span><span class="p">]</span>
            <span class="n">condition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">conditions</span><span class="p">[</span><span class="n">condition_name</span><span class="p">]</span>
            <span class="n">pts</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;pts&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">condition_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">conditions</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Something wrong happened.&quot;</span><span class="p">)</span>

            <span class="c1"># for data driven mode</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="s2">&quot;output_points&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;GAROM works only in data-driven mode.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># get data</span>
            <span class="n">snapshots</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">condition_idx</span> <span class="o">==</span> <span class="n">condition_id</span><span class="p">]</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="n">pts</span><span class="p">[</span><span class="n">condition_idx</span> <span class="o">==</span> <span class="n">condition_id</span><span class="p">]</span>

            <span class="n">d_loss_real</span><span class="p">,</span> <span class="n">d_loss_fake</span><span class="p">,</span> <span class="n">d_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_discriminator</span><span class="p">(</span>
                <span class="n">parameters</span><span class="p">,</span> <span class="n">snapshots</span>
            <span class="p">)</span>

            <span class="n">r_loss</span><span class="p">,</span> <span class="n">g_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_generator</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">snapshots</span><span class="p">)</span>

            <span class="n">diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights</span><span class="p">(</span><span class="n">d_loss_real</span><span class="p">,</span> <span class="n">d_loss_fake</span><span class="p">)</span>

            <span class="c1"># logging</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="s2">&quot;mean_loss&quot;</span><span class="p">,</span>
                <span class="nb">float</span><span class="p">(</span><span class="n">r_loss</span><span class="p">),</span>
                <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="s2">&quot;d_loss&quot;</span><span class="p">,</span>
                <span class="nb">float</span><span class="p">(</span><span class="n">d_loss</span><span class="p">),</span>
                <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="s2">&quot;g_loss&quot;</span><span class="p">,</span>
                <span class="nb">float</span><span class="p">(</span><span class="n">g_loss</span><span class="p">),</span>
                <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="s2">&quot;stability_metric&quot;</span><span class="p">,</span>
                <span class="nb">float</span><span class="p">(</span><span class="n">d_loss_real</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">)),</span>
                <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">optimizer_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">optimizer_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">scheduler_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">scheduler_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2024, PINA Contributors.
      <span class="lastupdated">Last updated on Jul 01, 2024.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>