<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorial: Averaging Neural Operator for solving Kuramoto Sivashinsky equation &mdash; PINA 0.1.0.post2405 documentation</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Tutorial: Unstructured convolutional autoencoder via continuous convolution" href="../tutorial4/tutorial.html" />
    <link rel="prev" title="Tutorial: Two dimensional Darcy flow using the Fourier Neural Operator" href="../tutorial5/tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/pina_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1.0.post2405
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Package Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../_code.html">API</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../_installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../_tutorial.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../_tutorial.html#getting-started-with-pina">Getting started with PINA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_tutorial.html#physics-informed-neural-networks">Physics Informed Neural Networks</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../_tutorial.html#neural-operator-learning">Neural Operator Learning</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../tutorial5/tutorial.html">Two dimensional Darcy flow using the Fourier Neural Operator</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Time dependent Kuramoto Sivashinsky equation using the Averaging Neural Operator</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#data-generation">Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#averaging-neural-operator">Averaging Neural Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#solving-the-ks-problem">Solving the KS problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#whats-next">What’s next?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../_tutorial.html#supervised-learning">Supervised Learning</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Community:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_team.html">Team &amp; Fundings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../_contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_LICENSE.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_cite.html">Cite PINA</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PINA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../_tutorial.html">PINA Tutorials</a></li>
      <li class="breadcrumb-item active">Tutorial: Averaging Neural Operator for solving Kuramoto Sivashinsky equation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/_rst/tutorials/tutorial10/tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="tutorial-averaging-neural-operator-for-solving-kuramoto-sivashinsky-equation">
<h1>Tutorial: Averaging Neural Operator for solving Kuramoto Sivashinsky equation<a class="headerlink" href="#tutorial-averaging-neural-operator-for-solving-kuramoto-sivashinsky-equation" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we will build a Neural Operator using the
<code class="docutils literal notranslate"><span class="pre">AveragingNeuralOperator</span></code> model and the <code class="docutils literal notranslate"><span class="pre">SupervisedSolver</span></code>. At the
end of the tutorial you will be able to train a Neural Operator for
learning the operator of time dependent PDEs.</p>
<p>First of all, some useful imports. Note we use <code class="docutils literal notranslate"><span class="pre">scipy</span></code> for i/o
operations.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import torch
import matplotlib.pyplot as plt
from scipy import io
from pina import Condition, LabelTensor
from pina.problem import AbstractProblem
from pina.model import AveragingNeuralOperator
from pina.solvers import SupervisedSolver
from pina.trainer import Trainer
</pre></div>
</div>
<div class="section" id="data-generation">
<h2>Data Generation<a class="headerlink" href="#data-generation" title="Permalink to this headline">¶</a></h2>
<p>We will focus on solving a specific PDE, the <strong>Kuramoto Sivashinsky</strong>
(KS) equation. The KS PDE is a fourth-order nonlinear PDE with the
following form:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial u}{\partial t}(x,t) = -u(x,t)\frac{\partial u}{\partial x}(x,t)- \frac{\partial^{4}u}{\partial x^{4}}(x,t) - \frac{\partial^{2}u}{\partial x^{2}}(x,t).\]</div>
<p>In the above <span class="math notranslate nohighlight">\(x\in \Omega=[0, 64]\)</span> represents a spatial location,
<span class="math notranslate nohighlight">\(t\in\mathbb{T}=[0,50]\)</span> the time and <span class="math notranslate nohighlight">\(u(x, t)\)</span> is the value
of the function <span class="math notranslate nohighlight">\(u:\Omega \times\mathbb{T}\in\mathbb{R}\)</span>. We
indicate with <span class="math notranslate nohighlight">\(\mathbb{U}\)</span> a suitable space for <span class="math notranslate nohighlight">\(u\)</span>, i.e. we
have that the solution <span class="math notranslate nohighlight">\(u\in\mathbb{U}\)</span>.</p>
<p>We impose Dirichlet boundary conditions on the derivative of <span class="math notranslate nohighlight">\(u\)</span>
on the border of the domain <span class="math notranslate nohighlight">\(\partial \Omega\)</span></p>
<div class="math notranslate nohighlight">
\[\frac{\partial u}{\partial x}(x,t)=0 \quad \forall (x,t)\in \partial \Omega\times\mathbb{T}.\]</div>
<p>Initial conditions are sampled from a distribution over truncated
Fourier series with random coefficients
<span class="math notranslate nohighlight">\(\{A_k, \ell_k, \phi_k\}_k\)</span> as</p>
<div class="math notranslate nohighlight">
\[u(x,0) = \sum_{k=1}^N A_k \sin(2 \pi \ell_k x / L + \phi_k) \ ,\]</div>
<p>where <span class="math notranslate nohighlight">\(A_k \in [-0.4, -0.3]\)</span>, <span class="math notranslate nohighlight">\(\ell_k = 2\)</span>,
<span class="math notranslate nohighlight">\(\phi_k = 2\pi \quad \forall k=1,\dots,N\)</span>.</p>
<p>We have already generated some data for differenti initial conditions,
and our objective will be to build a Neural Operator that, given
<span class="math notranslate nohighlight">\(u(x, t)\)</span> will output <span class="math notranslate nohighlight">\(u(x, t+\delta)\)</span>, where <span class="math notranslate nohighlight">\(\delta\)</span>
is a fixed time step. We will come back on the Neural Operator
architecture, for now we first need to import the data.</p>
<p><strong>Note:</strong> <em>The numerical integration is obtained by using pseudospectral
method for spatial derivative discratization and implicit Runge Kutta 5
for temporal dynamics.</em></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># load data
data=io.loadmat(&quot;dat/Data_KS.mat&quot;)

# converting to label tensor
initial_cond_train = LabelTensor(torch.tensor(data[&#39;initial_cond_train&#39;], dtype=torch.float), [&#39;t&#39;,&#39;x&#39;,&#39;u0&#39;])
initial_cond_test = LabelTensor(torch.tensor(data[&#39;initial_cond_test&#39;], dtype=torch.float), [&#39;t&#39;,&#39;x&#39;,&#39;u0&#39;])
sol_train = LabelTensor(torch.tensor(data[&#39;sol_train&#39;], dtype=torch.float), [&#39;u&#39;])
sol_test = LabelTensor(torch.tensor(data[&#39;sol_test&#39;], dtype=torch.float), [&#39;u&#39;])

print(&#39;Data Loaded&#39;)
print(f&#39; shape initial condition: {initial_cond_train.shape}&#39;)
print(f&#39; shape solution: {sol_train.shape}&#39;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Data</span> <span class="n">Loaded</span>
 <span class="n">shape</span> <span class="n">initial</span> <span class="n">condition</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">12800</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
 <span class="n">shape</span> <span class="n">solution</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">12800</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>The data are saved in the form <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">\times</span> <span class="pre">N</span> <span class="pre">\times</span> <span class="pre">D</span></code>, where <code class="docutils literal notranslate"><span class="pre">B</span></code> is
the batch_size (basically how many initial conditions we sample), <code class="docutils literal notranslate"><span class="pre">N</span></code>
the number of points in the mesh (which is the product of the
discretization in <code class="docutils literal notranslate"><span class="pre">x</span></code> timese the one in <code class="docutils literal notranslate"><span class="pre">t</span></code>), and <code class="docutils literal notranslate"><span class="pre">D</span></code> the
dimension of the problem (in this case we have three variables
<code class="docutils literal notranslate"><span class="pre">[u,</span> <span class="pre">t,</span> <span class="pre">x]</span></code>).</p>
<p>We are now going to plot some trajectories!</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># helper function
def plot_trajectory(coords, real, no_sol=None):
    # find the x-t shapes
    dim_x = len(torch.unique(coords.extract(&#39;x&#39;)))
    dim_t = len(torch.unique(coords.extract(&#39;t&#39;)))
    # if we don&#39;t have the Neural Operator solution we simply plot the real one
    if no_sol is None:
        fig, axs = plt.subplots(1, 1, figsize=(15, 5), sharex=True, sharey=True)
        c = axs.imshow(real.reshape(dim_t, dim_x).T.detach(),extent=[0, 50, 0, 64], cmap=&#39;PuOr_r&#39;, aspect=&#39;auto&#39;)
        axs.set_title(&#39;Real solution&#39;)
        fig.colorbar(c, ax=axs)
        axs.set_xlabel(&#39;t&#39;)
        axs.set_ylabel(&#39;x&#39;)
    # otherwise we plot the real one, the Neural Operator one, and their difference
    else:
        fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)
        axs[0].imshow(real.reshape(dim_t, dim_x).T.detach(),extent=[0, 50, 0, 64], cmap=&#39;PuOr_r&#39;, aspect=&#39;auto&#39;)
        axs[0].set_title(&#39;Real solution&#39;)
        axs[1].imshow(no_sol.reshape(dim_t, dim_x).T.detach(),extent=[0, 50, 0, 64], cmap=&#39;PuOr_r&#39;, aspect=&#39;auto&#39;)
        axs[1].set_title(&#39;NO solution&#39;)
        c = axs[2].imshow((real - no_sol).abs().reshape(dim_t, dim_x).T.detach(),extent=[0, 50, 0, 64], cmap=&#39;PuOr_r&#39;, aspect=&#39;auto&#39;)
        axs[2].set_title(&#39;Absolute difference&#39;)
        fig.colorbar(c, ax=axs.ravel().tolist())
        for ax in axs:
            ax.set_xlabel(&#39;t&#39;)
            ax.set_ylabel(&#39;x&#39;)
    plt.show()

# a sample trajectory (we use the sample 5, feel free to change)
sample_number = 20
plot_trajectory(coords=initial_cond_train[sample_number].extract([&#39;x&#39;, &#39;t&#39;]),
                real=sol_train[sample_number].extract(&#39;u&#39;))
</pre></div>
</div>
<img alt="../../../_images/tutorial_5_0.png" src="../../../_images/tutorial_5_0.png" />
<p>As we can see, as the time progresses the solution becomes chaotic,
which makes it really hard to learn! We will now focus on building a
Neural Operator using the <code class="docutils literal notranslate"><span class="pre">SupervisedSolver</span></code> class to tackle the
problem.</p>
</div>
<div class="section" id="averaging-neural-operator">
<h2>Averaging Neural Operator<a class="headerlink" href="#averaging-neural-operator" title="Permalink to this headline">¶</a></h2>
<p>We will build a neural operator <span class="math notranslate nohighlight">\(\texttt{NO}\)</span> which takes the
solution at time <span class="math notranslate nohighlight">\(t=0\)</span> for any <span class="math notranslate nohighlight">\(x\in\Omega\)</span>, the time
<span class="math notranslate nohighlight">\((t)\)</span> at which we want to compute the solution, and gives back the
solution to the KS equation <span class="math notranslate nohighlight">\(u(x, t)\)</span>, mathematically:</p>
<div class="math notranslate nohighlight">
\[\texttt{NO}_\theta : \mathbb{U} \rightarrow  \mathbb{U},\]</div>
<p>such that</p>
<div class="math notranslate nohighlight">
\[\texttt{NO}_\theta[u(t=0)](x, t) \rightarrow  u(x, t).\]</div>
<p>There are many ways on approximating the following operator, e.g. by 2D
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/fno.html">FNO</a> (for
regular meshes), a
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/deeponet.html">DeepOnet</a>,
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/layers/convolution.html">Continuous Convolutional Neural
Operator</a>,
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/mionet.html">MIONet</a>. In
this tutorial we will use the <em>Averaging Neural Operator</em> presented in
<a class="reference external" href="https://arxiv.org/abs/2304.13221">The Nonlocal Neural Operator: Universal
Approximation</a> which is a <a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/base_no.html">Kernel
Neural
Operator</a>
with integral kernel:</p>
<div class="math notranslate nohighlight">
\[K(v) = \sigma\left(Wv(x) + b + \frac{1}{|\Omega|}\int_\Omega v(y)dy\right)\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(v(x)\in\mathbb{R}^{\rm{emb}}\)</span> is the update for a function
<span class="math notranslate nohighlight">\(v\)</span> with <span class="math notranslate nohighlight">\(\mathbb{R}^{\rm{emb}}\)</span> the embedding (hidden)
size</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> is a non-linear activation</p></li>
<li><p><span class="math notranslate nohighlight">\(W\in\mathbb{R}^{\rm{emb}\times\rm{emb}}\)</span> is a tunable matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\(b\in\mathbb{R}^{\rm{emb}}\)</span> is a tunable bias.</p></li>
</ul>
<p>If PINA many Kernel Neural Operators are already implemented, and the
modular componets of the <a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/base_no.html">Kernel Neural
Operator</a>
class permits to create new ones by composing base kernel layers.</p>
<p><strong>Note:</strong>* We will use the already built class*
<code class="docutils literal notranslate"><span class="pre">AveragingNeuralOperator</span></code>, <em>as constructive excercise try to use the</em>
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/base_no.html">KernelNeuralOperator</a>
<em>class for building a kernel neural operator from scratch. You might
employ the different layers that we have in pina, e.g.</em>
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/models/fnn.html">FeedForward</a>,
<em>and</em>
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/layers/avno_layer.html">AveragingNeuralOperator</a>
<em>layers</em>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class SIREN(torch.nn.Module):
    def forward(self, x):
        return torch.sin(x)

embedding_dimesion = 40     # hyperparameter embedding dimension
input_dimension = 3         # [&#39;u&#39;, &#39;x&#39;, &#39;t&#39;]
number_of_coordinates = 2   # [&#39;x&#39;, &#39;t&#39;]
lifting_net = torch.nn.Linear(input_dimension, embedding_dimesion)   # simple linear layers for lifting and projecting nets
projecting_net = torch.nn.Linear(embedding_dimesion + number_of_coordinates, 1)
model = AveragingNeuralOperator(lifting_net=lifting_net,
                                projecting_net=projecting_net,
                                coordinates_indices=[&#39;x&#39;, &#39;t&#39;],
                                field_indices=[&#39;u0&#39;],
                                n_layers=4,
                                func=SIREN
                                )
</pre></div>
</div>
<p>Super easy! Notice that we use the <code class="docutils literal notranslate"><span class="pre">SIREN</span></code> activation function, more
on <a class="reference external" href="https://arxiv.org/abs/2006.09661">Implicit Neural Representations with Periodic Activation
Functions</a>.</p>
</div>
<div class="section" id="solving-the-ks-problem">
<h2>Solving the KS problem<a class="headerlink" href="#solving-the-ks-problem" title="Permalink to this headline">¶</a></h2>
<p>We will now focus on solving the KS equation using the
<code class="docutils literal notranslate"><span class="pre">SupervisedSolver</span></code> class and the <code class="docutils literal notranslate"><span class="pre">AveragingNeuralOperator</span></code> model. As
done in the <a class="reference external" href="https://github.com/mathLab/PINA/blob/master/tutorials/tutorial5/tutorial.ipynb">FNO
tutorial</a>
we now create the <code class="docutils literal notranslate"><span class="pre">NeuralOperatorProblem</span></code> class with
<code class="docutils literal notranslate"><span class="pre">AbstractProblem</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># expected running time ~ 1 minute

class NeuralOperatorProblem(AbstractProblem):
    input_variables = initial_cond_train.labels
    output_variables = sol_train.labels
    conditions = {&#39;data&#39; : Condition(input_points=initial_cond_train,
                                     output_points=sol_train)}


# initialize problem
problem = NeuralOperatorProblem()
# initialize solver
solver = SupervisedSolver(problem=problem, model=model,optimizer_kwargs={&quot;lr&quot;:0.001})
# train, only CPU and avoid model summary at beginning of training (optional)
trainer = Trainer(solver=solver, max_epochs=40, accelerator=&#39;cpu&#39;, enable_model_summary=False, log_every_n_steps=-1, batch_size=5) # we train on CPU and avoid model summary at beginning of training (optional)
trainer.train()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">True</span> <span class="p">(</span><span class="n">mps</span><span class="p">),</span> <span class="n">used</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">TPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">TPU</span> <span class="n">cores</span>
<span class="n">IPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">IPUs</span>
<span class="n">HPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">HPUs</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Epoch 39: 100%|██████████| 20/20 [00:01&lt;00:00, 13.59it/s, v_num=3, mean_loss=0.118]
</pre></div>
</div>
<pre class="literal-block"><cite>Trainer.fit</cite> stopped: <cite>max_epochs=40</cite> reached.</pre>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Epoch 39: 100%|██████████| 20/20 [00:01&lt;00:00, 13.56it/s, v_num=3, mean_loss=0.118]
</pre></div>
</div>
<p>We can now see some plots for the solutions</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sample_number = 2
no_sol = solver(initial_cond_test)
plot_trajectory(coords=initial_cond_test[sample_number].extract([&#39;x&#39;, &#39;t&#39;]),
                real=sol_test[sample_number].extract(&#39;u&#39;),
                no_sol=no_sol[5])
</pre></div>
</div>
<img alt="../../../_images/tutorial_11_0.png" src="../../../_images/tutorial_11_0.png" />
<p>As we can see we can obtain nice result considering the small trainint
time and the difficulty of the problem! Let’s see how the training and
testing error:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from pina.loss import PowerLoss

error_metric = PowerLoss(p=2)                                                   # we use the MSE loss

with torch.no_grad():
    no_sol_train = solver(initial_cond_train)
    err_train = error_metric(sol_train.extract(&#39;u&#39;), no_sol_train).mean()       # we average the error over trajectories
    no_sol_test = solver(initial_cond_test)
    err_test = error_metric(sol_test.extract(&#39;u&#39;),no_sol_test).mean()           # we average the error over trajectories
    print(f&#39;Training error: {float(err_train):.3f}&#39;)
    print(f&#39;Testing error: {float(err_test):.3f}&#39;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.128</span>
<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.119</span>
</pre></div>
</div>
<p>as we can see the error is pretty small, which agrees with what we can
see from the previous plots.</p>
</div>
<div class="section" id="whats-next">
<h2>What’s next?<a class="headerlink" href="#whats-next" title="Permalink to this headline">¶</a></h2>
<p>Now you know how to solve a time dependent neural operator problem in
<strong>PINA</strong>! There are multiple directions you can go now:</p>
<ol class="arabic simple">
<li><p>Train the network for longer or with different layer sizes and assert
the finaly accuracy</p></li>
<li><p>We left a more challenging dataset
<a class="reference external" href="https://github.com/mathLab/PINA/tree/master/tutorials/tutorial10/Data_KS2.mat">Data_KS2.mat</a> where
<span class="math notranslate nohighlight">\(A_k \in [-0.5, 0.5]\)</span>, <span class="math notranslate nohighlight">\(\ell_k \in [1, 2, 3]\)</span>,
<span class="math notranslate nohighlight">\(\phi_k \in [0, 2\pi]\)</span> for loger training</p></li>
<li><p>Compare the performance between the different neural operators (you
can even try to implement your favourite one!)</p></li>
</ol>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../tutorial5/tutorial.html" class="btn btn-neutral float-left" title="Tutorial: Two dimensional Darcy flow using the Fourier Neural Operator" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../tutorial4/tutorial.html" class="btn btn-neutral float-right" title="Tutorial: Unstructured convolutional autoencoder via continuous convolution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2024, PINA Contributors.
      <span class="lastupdated">Last updated on May 02, 2024.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>