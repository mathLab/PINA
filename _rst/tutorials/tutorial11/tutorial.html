
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Tutorial: PINA and PyTorch Lightning, training tips and visualizations &#8212; PINA 0.1.2.post2411 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="/css/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../../_static/documentation_options.js?v=b86f7f31"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_rst/tutorials/tutorial11/tutorial';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Tutorial: Building custom geometries with PINA Location class" href="../tutorial6/tutorial.html" />
    <link rel="prev" title="Tutorial: The Equation Class" href="../tutorial12/tutorial.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="0.1.2.post2411" />
    <meta name="docbuild:last-update" content="Nov 01, 2024"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/PINA_logo.png" class="logo__image only-light" alt="PINA 0.1.2.post2411 documentation - Home"/>
    <img src="../../../_static/PINA_logo.png" class="logo__image only-dark pst-js-only" alt="PINA 0.1.2.post2411 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../_installation.html">
    Installing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../_tutorial.html">
    Tutorial
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../_code.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../_team.html">
    Team & Foundings
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../_contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../_LICENSE.html">
    License
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../_cite.html">
    Cite PINA
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mathLab/PINA" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/pina_mathlab?s=21" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="mailto:pina.mathlab@gmail.com" title="Email" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Email</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../_installation.html">
    Installing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../_tutorial.html">
    Tutorial
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../_code.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../_team.html">
    Team & Foundings
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../_contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../_LICENSE.html">
    License
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../_cite.html">
    Cite PINA
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mathLab/PINA" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/pina_mathlab?s=21" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="mailto:pina.mathlab@gmail.com" title="Email" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Email</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tutorial1/tutorial.html">Introduction to PINA for Physics Informed Neural Networks training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial12/tutorial.html">Introduction to PINA Equation class</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">PINA and PyTorch Lightning, training tips and visualizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial6/tutorial.html">Building custom geometries with PINA Location class</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tutorial2/tutorial.html">Two dimensional Poisson problem using Extra Features Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial3/tutorial.html">Two dimensional Wave problem with hard constraint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial7/tutorial.html">Resolution of a 2D Poisson inverse problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial9/tutorial.html">Periodic Boundary Conditions for Helmotz Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial13/tutorial.html">Multiscale PDE learning with Fourier Feature Network</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tutorial5/tutorial.html">Two dimensional Darcy flow using the Fourier Neural Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial10/tutorial.html">Time dependent Kuramoto Sivashinsky equation using the Averaging Neural Operator</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tutorial4/tutorial.html">Unstructured convolutional autoencoder via continuous convolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial8/tutorial.html">POD-RBF and POD-NN for reduced order modeling</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../_tutorial.html" class="nav-link">PINA Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Tutorial: PINA and PyTorch Lightning, training tips and visualizations</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="tutorial-pina-and-pytorch-lightning-training-tips-and-visualizations">
<h1>Tutorial: PINA and PyTorch Lightning, training tips and visualizations<a class="headerlink" href="#tutorial-pina-and-pytorch-lightning-training-tips-and-visualizations" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/mathLab/PINA/blob/master/tutorials/tutorial11/tutorial.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>In this tutorial, we will delve deeper into the functionality of the
<code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class, which serves as the cornerstone for training <strong>PINA</strong>
<a class="reference external" href="https://mathlab.github.io/PINA/_rst/_code.html#solvers">Solvers</a>.
The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class offers a plethora of features aimed at improving
model accuracy, reducing training time and memory usage, facilitating
logging visualization, and more thanks to the amazing job done by the PyTorch Lightning team!
Our leading example will revolve around solving the <code class="docutils literal notranslate"><span class="pre">SimpleODE</span></code>
problem, as outlined in the <a class="reference external" href="https://github.com/mathLab/PINA/blob/master/tutorials/tutorial1/tutorial.ipynb">Introduction to PINA for Physics Informed
Neural Networks
training</a>.
If you haven’t already explored it, we highly recommend doing so before
diving into this tutorial.
Let’s start by importing useful modules, define the <code class="docutils literal notranslate"><span class="pre">SimpleODE</span></code>
problem and the <code class="docutils literal notranslate"><span class="pre">PINN</span></code> solver.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>## routine needed to run the notebook on Google Colab
try:
  import google.colab
  IN_COLAB = True
except:
  IN_COLAB = False
if IN_COLAB:
  !pip install &quot;pina-mathlab&quot;

import torch

from pina import Condition, Trainer
from pina.solvers import PINN
from pina.model import FeedForward
from pina.problem import SpatialProblem
from pina.operators import grad
from pina.geometry import CartesianDomain
from pina.equation import Equation, FixedValue

class SimpleODE(SpatialProblem):

    output_variables = [&#39;u&#39;]
    spatial_domain = CartesianDomain({&#39;x&#39;: [0, 1]})

    # defining the ode equation
    def ode_equation(input_, output_):
        u_x = grad(output_, input_, components=[&#39;u&#39;], d=[&#39;x&#39;])
        u = output_.extract([&#39;u&#39;])
        return u_x - u

    # conditions to hold
    conditions = {
        &#39;x0&#39;: Condition(location=CartesianDomain({&#39;x&#39;: 0.}), equation=FixedValue(1)),             # We fix initial condition to value 1
        &#39;D&#39;: Condition(location=CartesianDomain({&#39;x&#39;: [0, 1]}), equation=Equation(ode_equation)), # We wrap the python equation using Equation
    }

    # defining the true solution
    def truth_solution(self, pts):
        return torch.exp(pts.extract([&#39;x&#39;]))


# sampling for training
problem = SimpleODE()
problem.discretise_domain(1, &#39;random&#39;, locations=[&#39;x0&#39;])
problem.discretise_domain(20, &#39;lh&#39;, locations=[&#39;D&#39;])

# build the model
model = FeedForward(
    layers=[10, 10],
    func=torch.nn.Tanh,
    output_dimensions=len(problem.output_variables),
    input_dimensions=len(problem.input_variables)
)

# create the PINN object
pinn = PINN(problem, model)
</pre></div>
</div>
<p>Till now we just followed the extact step of the previous tutorials. The
<code class="docutils literal notranslate"><span class="pre">Trainer</span></code> object can be initialized by simiply passing the <code class="docutils literal notranslate"><span class="pre">PINN</span></code>
solver</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>trainer = Trainer(solver=pinn)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">True</span> <span class="p">(</span><span class="n">mps</span><span class="p">),</span> <span class="n">used</span><span class="p">:</span> <span class="kc">True</span>
<span class="n">TPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">TPU</span> <span class="n">cores</span>
<span class="n">IPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">IPUs</span>
<span class="n">HPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">HPUs</span>
</pre></div>
</div>
<section id="trainer-accelerator">
<h2>Trainer Accelerator<a class="headerlink" href="#trainer-accelerator" title="Link to this heading">#</a></h2>
<p>When creating the trainer, <strong>by defualt</strong> the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> will choose
the most performing <code class="docutils literal notranslate"><span class="pre">accelerator</span></code> for training which is available in
your system, ranked as follow:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://cloud.google.com/tpu/docs/intro-to-tpu">TPU</a></p></li>
<li><p><a class="reference external" href="https://www.graphcore.ai/products/ipu">IPU</a></p></li>
<li><p><a class="reference external" href="https://habana.ai/">HPU</a></p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html#:~:text=What%20does%20GPU%20stand%20for,video%20editing%2C%20and%20gaming%20applications">GPU</a> or <a class="reference external" href="https://developer.apple.com/metal/pytorch/">MPS</a></p></li>
<li><p>CPU</p></li>
</ol>
<p>For setting manually the <code class="docutils literal notranslate"><span class="pre">accelerator</span></code> run:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">accelerator</span> <span class="pre">=</span> <span class="pre">{'gpu',</span> <span class="pre">'cpu',</span> <span class="pre">'hpu',</span> <span class="pre">'mps',</span> <span class="pre">'cpu',</span> <span class="pre">'ipu'}</span></code> sets the
accelerator to a specific one</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>trainer = Trainer(solver=pinn,
                  accelerator=&#39;cpu&#39;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">True</span> <span class="p">(</span><span class="n">mps</span><span class="p">),</span> <span class="n">used</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">TPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">TPU</span> <span class="n">cores</span>
<span class="n">IPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">IPUs</span>
<span class="n">HPU</span> <span class="n">available</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="n">using</span><span class="p">:</span> <span class="mi">0</span> <span class="n">HPUs</span>
</pre></div>
</div>
<p>as you can see, even if in the used system <code class="docutils literal notranslate"><span class="pre">GPU</span></code> is available, it is
not used since we set <code class="docutils literal notranslate"><span class="pre">accelerator='cpu'</span></code>.</p>
</section>
<section id="trainer-logging">
<h2>Trainer Logging<a class="headerlink" href="#trainer-logging" title="Link to this heading">#</a></h2>
<p>In <strong>PINA</strong> you can log metrics in different ways. The simplest approach
is to use the <code class="docutils literal notranslate"><span class="pre">MetricTraker</span></code> class from <code class="docutils literal notranslate"><span class="pre">pina.callbacks</span></code> as seen in
the <a class="reference external" href="https://github.com/mathLab/PINA/blob/master/tutorials/tutorial1/tutorial.ipynb">Introduction to PINA for Physics Informed Neural Networks
training</a>
tutorial.</p>
<p>However, expecially when we need to train multiple times to get an
average of the loss across multiple runs, <code class="docutils literal notranslate"><span class="pre">pytorch_lightning.loggers</span></code>
might be useful. Here we will use <code class="docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code> (more on
<a class="reference external" href="https://lightning.ai/docs/pytorch/stable/extensions/logging.html">logging</a>
here), but you can choose the one you prefer (or make your own one).</p>
<p>We will now import <code class="docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code>, do three runs of training and
then visualize the results. Notice we set <code class="docutils literal notranslate"><span class="pre">enable_model_summary=False</span></code>
to avoid model summary specifications (e.g. number of parameters), set
it to true if needed.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from pytorch_lightning.loggers import TensorBoardLogger

# three run of training, by default it trains for 1000 epochs
# we reinitialize the model each time otherwise the same parameters will be optimized
for _ in range(3):
    model = FeedForward(
        layers=[10, 10],
        func=torch.nn.Tanh,
        output_dimensions=len(problem.output_variables),
        input_dimensions=len(problem.input_variables)
    )
    pinn = PINN(problem, model)
    trainer = Trainer(solver=pinn,
                      accelerator=&#39;cpu&#39;,
                      logger=TensorBoardLogger(save_dir=&#39;simpleode&#39;),
                      enable_model_summary=False)
    trainer.train()
</pre></div>
</div>
<pre class="literal-block">GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

<cite>Trainer.fit</cite> stopped: <cite>max_epochs=1000</cite> reached.
Epoch 999: 100%|██████████| 1/1 [00:00&lt;00:00, 133.46it/s, v_num=6, x0_loss=1.48e-5, D_loss=0.000655, mean_loss=0.000335]</pre>
<pre class="literal-block">GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

<cite>Trainer.fit</cite> stopped: <cite>max_epochs=1000</cite> reached.
Epoch 999: 100%|██████████| 1/1 [00:00&lt;00:00, 154.49it/s, v_num=7, x0_loss=6.21e-6, D_loss=0.000221, mean_loss=0.000114]</pre>
<pre class="literal-block">GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

<cite>Trainer.fit</cite> stopped: <cite>max_epochs=1000</cite> reached.
Epoch 999: 100%|██████████| 1/1 [00:00&lt;00:00, 62.60it/s, v_num=8, x0_loss=1.44e-5, D_loss=0.000572, mean_loss=0.000293]</pre>
<p>We can now visualize the logs by simply running
<code class="docutils literal notranslate"><span class="pre">tensorboard</span> <span class="pre">--logdir=simpleode/</span></code> on terminal, you should obtain a
webpage as the one shown below:</p>
<img alt="../../../_images/logging.png" src="../../../_images/logging.png" />
<p>as you can see, by default, <strong>PINA</strong> logs the losses which are shown in
the progress bar, as well as the number of epochs. You can always insert
more loggings by either defining a <strong>callback</strong> (<a class="reference external" href="https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html">more on
callbacks</a>),
or inheriting the solver and modify the programs with different
<strong>hooks</strong> (<a class="reference external" href="https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#hooks">more on
hooks</a>).</p>
</section>
<section id="trainer-callbacks">
<h2>Trainer Callbacks<a class="headerlink" href="#trainer-callbacks" title="Link to this heading">#</a></h2>
<p>Whenever we need to access certain steps of the training for logging, do
static modifications (i.e. not changing the <code class="docutils literal notranslate"><span class="pre">Solver</span></code>) or updating
<code class="docutils literal notranslate"><span class="pre">Problem</span></code> hyperparameters (static variables), we can use
<code class="docutils literal notranslate"><span class="pre">Callabacks</span></code>. Notice that <code class="docutils literal notranslate"><span class="pre">Callbacks</span></code> allow you to add arbitrary
self-contained programs to your training. At specific points during the
flow of execution (hooks), the Callback interface allows you to design
programs that encapsulate a full set of functionality. It de-couples
functionality that does not need to be in <strong>PINA</strong> <code class="docutils literal notranslate"><span class="pre">Solver</span></code>s.
Lightning has a callback system to execute them when needed. Callbacks
should capture NON-ESSENTIAL logic that is NOT required for your
lightning module to run.</p>
<p>The following are best practices when using/designing callbacks.</p>
<ul class="simple">
<li><p>Callbacks should be isolated in their functionality.</p></li>
<li><p>Your callback should not rely on the behavior of other callbacks in
order to work properly.</p></li>
<li><p>Do not manually call methods from the callback.</p></li>
<li><p>Directly calling methods (eg. on_validation_end) is strongly
discouraged.</p></li>
<li><p>Whenever possible, your callbacks should not depend on the order in
which they are executed.</p></li>
</ul>
<p>We will try now to implement a naive version of <code class="docutils literal notranslate"><span class="pre">MetricTraker</span></code> to show
how callbacks work. Notice that this is a very easy application of
callbacks, fortunately in <strong>PINA</strong> we already provide more advanced
callbacks in <code class="docutils literal notranslate"><span class="pre">pina.callbacks</span></code>.</p>
<!-- Suppose we want to log the accuracy on some validation poit --><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from pytorch_lightning.callbacks import Callback
import torch

# define a simple callback
class NaiveMetricTracker(Callback):
    def __init__(self):
        self.saved_metrics = []

    def on_train_epoch_end(self, trainer, __): # function called at the end of each epoch
        self.saved_metrics.append(
            {key: value for key, value in trainer.logged_metrics.items()}
        )
</pre></div>
</div>
<p>Let’s see the results when applyed to the <code class="docutils literal notranslate"><span class="pre">SimpleODE</span></code> problem. You can
define callbacks when initializing the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> by the <code class="docutils literal notranslate"><span class="pre">callbacks</span></code>
argument, which expects a list of callbacks.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model = FeedForward(
        layers=[10, 10],
        func=torch.nn.Tanh,
        output_dimensions=len(problem.output_variables),
        input_dimensions=len(problem.input_variables)
    )
pinn = PINN(problem, model)
trainer = Trainer(solver=pinn,
                  accelerator=&#39;cpu&#39;,
                  enable_model_summary=False,
                  callbacks=[NaiveMetricTracker()])  # adding a callbacks
trainer.train()
</pre></div>
</div>
<pre class="literal-block">GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

<cite>Trainer.fit</cite> stopped: <cite>max_epochs=1000</cite> reached.
Epoch 999: 100%|██████████| 1/1 [00:00&lt;00:00, 149.27it/s, v_num=1, x0_loss=7.27e-5, D_loss=0.0016, mean_loss=0.000838]</pre>
<p>We can easily access the data by calling
<code class="docutils literal notranslate"><span class="pre">trainer.callbacks[0].saved_metrics</span></code> (notice the zero representing the
first callback in the list given at initialization).</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>trainer.callbacks[0].saved_metrics[:3] # only the first three epochs
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span><span class="s1">&#39;x0_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.9141</span><span class="p">),</span>
  <span class="s1">&#39;D_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.0304</span><span class="p">),</span>
  <span class="s1">&#39;mean_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.4722</span><span class="p">)},</span>
 <span class="p">{</span><span class="s1">&#39;x0_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.8906</span><span class="p">),</span>
  <span class="s1">&#39;D_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.0287</span><span class="p">),</span>
  <span class="s1">&#39;mean_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.4596</span><span class="p">)},</span>
 <span class="p">{</span><span class="s1">&#39;x0_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.8674</span><span class="p">),</span>
  <span class="s1">&#39;D_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.0274</span><span class="p">),</span>
  <span class="s1">&#39;mean_loss&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.4474</span><span class="p">)}]</span>
</pre></div>
</div>
<p>PyTorch Lightning also has some built in <code class="docutils literal notranslate"><span class="pre">Callbacks</span></code> which can be used
in <strong>PINA</strong>, <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html#built-in-callbacks">here an extensive
list</a>.</p>
<p>We can for example try the <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> routine, which
automatically stops the training when a specific metric converged (here
the <code class="docutils literal notranslate"><span class="pre">mean_loss</span></code>). In order to let the training keep going forever set
<code class="docutils literal notranslate"><span class="pre">max_epochs=-1</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># ~2 mins
from pytorch_lightning.callbacks import EarlyStopping

model = FeedForward(
        layers=[10, 10],
        func=torch.nn.Tanh,
        output_dimensions=len(problem.output_variables),
        input_dimensions=len(problem.input_variables)
    )
pinn = PINN(problem, model)
trainer = Trainer(solver=pinn,
                  accelerator=&#39;cpu&#39;,
                  max_epochs = -1,
                  enable_model_summary=False,
                  callbacks=[EarlyStopping(&#39;mean_loss&#39;)])  # adding a callbacks
trainer.train()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

Epoch 6157: 100%|██████████| 1/1 [00:00&lt;00:00, 139.84it/s, v_num=9, x0_loss=4.21e-9, D_loss=9.93e-6, mean_loss=4.97e-6]
</pre></div>
</div>
<p>As we can see the model automatically stop when the logging metric
stopped improving!</p>
</section>
<section id="trainer-tips-to-boost-accuracy-save-memory-and-speed-up-training">
<h2>Trainer Tips to Boost Accuracy, Save Memory and Speed Up Training<a class="headerlink" href="#trainer-tips-to-boost-accuracy-save-memory-and-speed-up-training" title="Link to this heading">#</a></h2>
<p>Untill now we have seen how to choose the right <code class="docutils literal notranslate"><span class="pre">accelerator</span></code>, how to
log and visualize the results, and how to interface with the program in
order to add specific parts of code at specific points by <code class="docutils literal notranslate"><span class="pre">callbacks</span></code>.
Now, we well focus on how boost your training by saving memory and
speeding it up, while mantaining the same or even better degree of
accuracy!</p>
<p>There are several built in methods developed in PyTorch Lightning which
can be applied straight forward in <strong>PINA</strong>, here we report some:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/">Stochastic Weight
Averaging</a>
to boost accuracy</p></li>
<li><p><a class="reference external" href="https://deepgram.com/ai-glossary/gradient-clipping">Gradient
Clippling</a> to
reduce computational time (and improve accuracy)</p></li>
<li><p><a class="reference external" href="https://lightning.ai/docs/pytorch/stable/common/optimization.html#id3">Gradient
Accumulation</a>
to save memory consumption</p></li>
<li><p><a class="reference external" href="https://lightning.ai/docs/pytorch/stable/common/optimization.html#id3">Mixed Precision
Training</a>
to save memory consumption</p></li>
</ul>
<p>We will just demonstrate how to use the first two, and see the results
compared to a standard training. We use the
<a class="reference external" href="https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.Timer.html#lightning.pytorch.callbacks.Timer">Timer</a>
callback from <code class="docutils literal notranslate"><span class="pre">pytorch_lightning.callbacks</span></code> to take the times. Let’s
start by training a simple model without any optimization (train for
2000 epochs).</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from pytorch_lightning.callbacks import Timer
from pytorch_lightning import seed_everything

# setting the seed for reproducibility
seed_everything(42, workers=True)

model = FeedForward(
        layers=[10, 10],
        func=torch.nn.Tanh,
        output_dimensions=len(problem.output_variables),
        input_dimensions=len(problem.input_variables)
    )

pinn = PINN(problem, model)
trainer = Trainer(solver=pinn,
                  accelerator=&#39;cpu&#39;,
                  deterministic=True,  # setting deterministic=True ensure reproducibility when a seed is imposed
                  max_epochs = 2000,
                  enable_model_summary=False,
                  callbacks=[Timer()])  # adding a callbacks
trainer.train()
print(f&#39;Total training time {trainer.callbacks[0].time_elapsed(&quot;train&quot;):.5f} s&#39;)
</pre></div>
</div>
<pre class="literal-block">Seed set to 42
GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs


<cite>Trainer.fit</cite> stopped: <cite>max_epochs=2000</cite> reached.
Epoch 1999: 100%|██████████| 1/1 [00:00&lt;00:00, 163.58it/s, v_num=31, x0_loss=1.12e-6, D_loss=0.000127, mean_loss=6.4e-5]
Total training time 17.36381 s</pre>
<p>Now we do the same but with StochasticWeightAveraging</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from pytorch_lightning.callbacks import StochasticWeightAveraging

# setting the seed for reproducibility
seed_everything(42, workers=True)

model = FeedForward(
        layers=[10, 10],
        func=torch.nn.Tanh,
        output_dimensions=len(problem.output_variables),
        input_dimensions=len(problem.input_variables)
    )
pinn = PINN(problem, model)
trainer = Trainer(solver=pinn,
                  accelerator=&#39;cpu&#39;,
                  deterministic=True,
                  max_epochs = 2000,
                  enable_model_summary=False,
                  callbacks=[Timer(),
                             StochasticWeightAveraging(swa_lrs=0.005)])  # adding StochasticWeightAveraging callbacks
trainer.train()
print(f&#39;Total training time {trainer.callbacks[0].time_elapsed(&quot;train&quot;):.5f} s&#39;)
</pre></div>
</div>
<pre class="literal-block">Seed set to 42
GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs


Epoch 1598: 100%|██████████| 1/1 [00:00&lt;00:00, 210.04it/s, v_num=47, x0_loss=4.17e-6, D_loss=0.000204, mean_loss=0.000104]
Swapping scheduler <cite>ConstantLR</cite> for <cite>SWALR</cite>
<cite>Trainer.fit</cite> stopped: <cite>max_epochs=2000</cite> reached.
Epoch 1999: 100%|██████████| 1/1 [00:00&lt;00:00, 120.85it/s, v_num=47, x0_loss=1.56e-7, D_loss=7.49e-5, mean_loss=3.75e-5]
Total training time 17.10627 s</pre>
<p>As you can see, the training time does not change at all! Notice that
around epoch <code class="docutils literal notranslate"><span class="pre">1600</span></code> the scheduler is switched from the defalut one
<code class="docutils literal notranslate"><span class="pre">ConstantLR</span></code> to the Stochastic Weight Average Learning Rate
(<code class="docutils literal notranslate"><span class="pre">SWALR</span></code>). This is because by default <code class="docutils literal notranslate"><span class="pre">StochasticWeightAveraging</span></code>
will be activated after <code class="docutils literal notranslate"><span class="pre">int(swa_epoch_start</span> <span class="pre">*</span> <span class="pre">max_epochs)</span></code> with
<code class="docutils literal notranslate"><span class="pre">swa_epoch_start=0.7</span></code> by default. Finally, the final <code class="docutils literal notranslate"><span class="pre">mean_loss</span></code> is
lower when <code class="docutils literal notranslate"><span class="pre">StochasticWeightAveraging</span></code> is used.</p>
<p>We will now now do the same but clippling the gradient to be relatively
small.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># setting the seed for reproducibility
seed_everything(42, workers=True)

model = FeedForward(
        layers=[10, 10],
        func=torch.nn.Tanh,
        output_dimensions=len(problem.output_variables),
        input_dimensions=len(problem.input_variables)
    )
pinn = PINN(problem, model)
trainer = Trainer(solver=pinn,
                  accelerator=&#39;cpu&#39;,
                  max_epochs = 2000,
                  enable_model_summary=False,
                  gradient_clip_val=0.1,          # clipping the gradient
                  callbacks=[Timer(),
                             StochasticWeightAveraging(swa_lrs=0.005)])
trainer.train()
print(f&#39;Total training time {trainer.callbacks[0].time_elapsed(&quot;train&quot;):.5f} s&#39;)
</pre></div>
</div>
<pre class="literal-block">Seed set to 42
GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

Epoch 1598: 100%|██████████| 1/1 [00:00&lt;00:00, 261.80it/s, v_num=46, x0_loss=9e-8, D_loss=2.39e-5, mean_loss=1.2e-5]
Swapping scheduler <cite>ConstantLR</cite> for <cite>SWALR</cite>
<cite>Trainer.fit</cite> stopped: <cite>max_epochs=2000</cite> reached.
Epoch 1999: 100%|██████████| 1/1 [00:00&lt;00:00, 148.99it/s, v_num=46, x0_loss=7.08e-7, D_loss=1.77e-5, mean_loss=9.19e-6]
Total training time 17.01149 s</pre>
<p>As we can see we by applying gradient clipping we were able to even
obtain lower error!</p>
</section>
<section id="whats-next">
<h2>What’s next?<a class="headerlink" href="#whats-next" title="Link to this heading">#</a></h2>
<p>Now you know how to use efficiently the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class <strong>PINA</strong>!
There are multiple directions you can go now:</p>
<ol class="arabic simple">
<li><p>Explore training times on different devices (e.g.) <code class="docutils literal notranslate"><span class="pre">TPU</span></code></p></li>
<li><p>Try to reduce memory cost by mixed precision training and gradient
accumulation (especially useful when training Neural Operators)</p></li>
<li><p>Benchmark <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> speed for different precisions.</p></li>
</ol>
</section>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-accelerator">Trainer Accelerator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-logging">Trainer Logging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-callbacks">Trainer Callbacks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-tips-to-boost-accuracy-save-memory-and-speed-up-training">Trainer Tips to Boost Accuracy, Save Memory and Speed Up Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What’s next?</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../../../_sources/_rst/tutorials/tutorial11/tutorial.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2021-2024, PINA Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.0.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>